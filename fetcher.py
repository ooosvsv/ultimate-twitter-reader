import json
import urllib.request
import re
import argparse
import hashlib
from datetime import datetime, timezone

def fetch_with_fallback(tweet_id):
    """å¤šç«¯ç‚¹å®¹ç¾ï¼šé¦–é€‰ vxtwitterï¼Œå¤±è´¥æ— ç¼åˆ‡æ¢ fxtwitter"""
    endpoints = [
        f"https://api.vxtwitter.com/Twitter/status/{tweet_id}",
        f"https://api.fxtwitter.com/Twitter/status/{tweet_id}"
    ]
    for api_url in endpoints:
        req = urllib.request.Request(api_url, headers={'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64)'})
        try:
            with urllib.request.urlopen(req, timeout=10) as response:
                return json.loads(response.read().decode('utf-8'))
        except Exception:
            continue
    return {"error": "æ¨æ–‡å¯èƒ½å·²è¢«åˆ é™¤ã€è®¾ç½®ä¸ºç§å¯†ï¼Œæˆ–ç«¯ç‚¹æš‚æ—¶ä¸å¯ç”¨ã€‚"}

def format_deepreeder_md(data, original_url):
    """èåˆ DeepReeder é£æ ¼ï¼Œç”Ÿæˆç»“æ„åŒ– Markdown"""
    if "error" in data:
        return f"âŒ [æŠ“å–å¤±è´¥]({original_url}): {data['error']}\n"

    text = data.get("text", "")
    author_name = data.get("user_name", "Unknown")
    author_handle = data.get("user_screen_name", "unknown")
    date_str = data.get("date", datetime.now(timezone.utc).strftime("%Y-%m-%dT%H:%M:%SZ"))
    likes = data.get("likes", 0)
    retweets = data.get("retweets", 0)
    content_hash = hashlib.sha256(text.encode('utf-8')).hexdigest()[:12]

    # æ„å»º YAML å…ƒæ•°æ®å’Œæ­£æ–‡
    md = f"""---
author: "@{author_handle}"
source: "{original_url}"
date: "{date_str}"
content_hash: "{content_hash}"
---

### ğŸ¦ {author_name} (@{author_handle})

ğŸ•’ æ—¶é—´: {date_str} | ğŸ“Š äº’åŠ¨: â¤ï¸ {likes} Â· ğŸ” {retweets}

> {text.replace(chr(10), chr(10) + '> ')}
"""

    # å¤„ç†åª’ä½“ï¼šæ ¼å¼åŒ–ä¸ºæ ‡å‡† Markdown å›¾ç‰‡è¯­æ³•ï¼Œä»¥ä¾¿å¤§æ¨¡å‹è§¦å‘ Vision èƒ½åŠ›
    media_list = data.get("mediaURLs", [])
    if media_list:
        md += "\n**ğŸ“¸ é™„å¸¦åª’ä½“ (Media):**\n"
        for i, url in enumerate(media_list):
            if "video" in url or ".mp4" in url:
                md += f"- ğŸ¥ [ç‚¹å‡»æŸ¥çœ‹è§†é¢‘æºæ–‡ä»¶]({url})\n"
            else:
                md += f"![Image_{i}]({url})\n"

    return md

if __name__ == "__main__":
    parser = argparse.ArgumentParser(description="Ultimate Twitter Fetcher")
    parser.add_argument("--urls", required=True, help="åŒ…å« X/Twitter é“¾æ¥çš„ä¸€æ®µæ–‡æœ¬")
    args = parser.parse_args()

    # ä½¿ç”¨æ­£åˆ™ä¸€æ¬¡æ€§æå–è¾“å…¥æ–‡æœ¬ä¸­çš„æ‰€æœ‰æ¨æ–‡ IDï¼ˆæ”¯æŒæ‰¹é‡æŠ“å–ï¼‰
    tweet_ids = set(re.findall(r'(?:twitter\.com|x\.com)/[a-zA-Z0-9_]+/status/([0-9]+)', args.urls))

    if not tweet_ids:
        print("âš ï¸ æœªåœ¨è¾“å…¥ä¸­æ£€æµ‹åˆ°æœ‰æ•ˆçš„ Twitter/X é“¾æ¥ã€‚")
        exit(1)

    print("### ğŸ” æŠ“å–ç»“æœ\n")

    for tid in tweet_ids:
        url = f"https://x.com/i/status/{tid}"
        data = fetch_with_fallback(tid)
        print(format_deepreeder_md(data, url))
        print("\n---\n")
